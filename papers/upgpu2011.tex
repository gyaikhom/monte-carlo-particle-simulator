\documentclass[a4paper]{article}
\usepackage{fullpage}

\begin{document}
\begin{center}
{\Large\bf Hybrid Multi-threaded Radiotherapy Monte Carlo Simulations}

\vspace*{1cm}

{\large Gagarine Yaikhom\quad \quad \quad David W. Walker}

\bigskip

School of Computer Science and Informatics\\
Cardiff University, United Kingdom CF24 3AA
\end{center}

\vspace*{0.15cm}

Radiotherapy dose calculation relies on the simulation of the physical interaction between sub-atomic particles and matter. The human tissues of the patient are modelled as a volumetric phantom of material properties, while the radiation is modelled as a set of particles generated by a linear accelerator model. To reduce the harmful effects of radiation on the healthy tissues, the radiation dosage must be calculated accurately, so that it is applied only to the specific tumours that are being treated.

The Monte Carlo radiotherapy simulation, which simulates the physics of randomised radiation particles, is an important computational technique that is able to deliver accurate radiotherapy dosage. With this technique, we can increase the accuracy of the dosage by simply increasing the number of particles simulated. However, increasing the number of particles also increases the overall simulation time. Hence, the aim is to reduce the simulation time by exploiting parallelism.

The scientific basis for the Monte Carlo simulation technique is that, given a sufficient number of cases, a simulation will produce results that are close to the actual result one would obtain if a brute-force technique had been used. Hence, the key to drawing out the maximum performance and efficiency from a Monte Carlo simulation lies in parallelising across the number of cases. In this talk, we will discuss our ongoing work to parallelise Monte Carlo radiotherapy simulations using hybrid multithreading using GPUs and multicore CPUs. We will discuss how we are addressing the following challenges:

\begin{itemize}
\item {\bf Generation of secondary particles} In both Nvidia CUDA and OpenCL, the symmetric processors on the GPU devices work in response to the demands of the host application (i.e., kernel invocations). Even the management of the memory on the GPU devices is done by the host application. During the simulation, however, when the device kernels are simulating the interaction of particles with matter, there is a possibility that the physics processes would generate multiple secondary particles on the GPU device. Since device memory is only managed by the host application, the challenge is to create thread-safe data structures that will allow the running kernels to create new particles inside the GPU devices without explicitly allocating memory on the devices.

\item {\bf Data transfer costs} For every GPU kernel invocation, we must transfer the required data from the host application to the GPU device memory. Furthermore, we must transfer the results of the computation from the GPU devices to the host application. The challenge, therefore, is to minimise the number of data transfers required, so that immutable data (e.g., geometry data, physics tables) are initialised and stored only once, preferably as lookup tables in the high-bandwidth texture memory; and data that are unique to each kernel invocation are designed to be compact and efficient (e.g., tabular representation of the tree data structures which define the simulation world).

\item {\bf Register spillage} In the GPU architecture, each of the threads in the streaming multiprocessor is allocated a limited number of registers. When the device kernels are compiled, it is important that the compiler does not exceed the usage of registers beyond this limit, or else data will spill over to memory, which comes with additional memory access costs. Since radiotherapy simulation consists of complex geometric and physics computations, we must design data structures and algorithms that are compact and simple, so that all of the computations fit within the register limit. In the talk, we will discuss, e.g., the usage of postfix expressions to represent the simulation world, and how space is divided in relation to the compute blocks. 

\item {\bf Cache efficiency} Since the simulations are happening inside a closed bounded space, it is highly likely that many of the particles will share some of the geometric and physics data. Hence, while dividing the particles into simulation blocks, the aim is to take advantage of the memory hierarchy of the GPU devices, so that threads that are inside the same block share the same set of geometric and physics data. We shall discuss how uniform division of the simulation world allows effective utilisation of the data cache, and how compact representation of the algorithms (such as the use of postfix expressions) increases the utilisation of the instruction cache.
\end{itemize}

\end{document}
